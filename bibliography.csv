"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"BHA9Y28U","journalArticle","2015","Ganin, Yaroslav; Ustinova, Evgeniya; Ajakan, Hana; Germain, Pascal; Larochelle, Hugo; Laviolette, François; Marchand, Mario; Lempitsky, Victor","Domain-Adversarial Training of Neural Networks","","","","10.48550/arXiv.1505.07818","https://arxiv.org/abs/1505.07818v4","We introduce a new representation learning approach for domain adaptation, in which data at training and test time come from similar but different distributions. Our approach is directly inspired by the theory on domain adaptation suggesting that, for effective domain transfer to be achieved, predictions must be made based on features that cannot discriminate between the training (source) and test (target) domains. The approach implements this idea in the context of neural network architectures that are trained on labeled data from the source domain and unlabeled data from the target domain (no labeled target-domain data is necessary). As the training progresses, the approach promotes the emergence of features that are (i) discriminative for the main learning task on the source domain and (ii) indiscriminate with respect to the shift between the domains. We show that this adaptation behaviour can be achieved in almost any feed-forward model by augmenting it with few standard layers and a new gradient reversal layer. The resulting augmented architecture can be trained using standard backpropagation and stochastic gradient descent, and can thus be implemented with little effort using any of the deep learning packages. We demonstrate the success of our approach for two distinct classification problems (document sentiment analysis and image classification), where state-of-the-art domain adaptation performance on standard benchmarks is achieved. We also validate the approach for descriptor learning task in the context of person re-identification application.","2015-05-28","2022-06-07 01:12:13","2023-05-14 16:47:31","2022-06-07 01:12:13","","","","","","","","","","","","","","en","","","","","arxiv.org","","","","/Users/patrickmineault/Zotero/storage/X5N5UKQH/Ganin et al. - 2016 - Domain-adversarial training of neural networks.pdf; /Users/patrickmineault/Zotero/storage/JS7GWRX7/1505.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YKG67LQA","preprint","2020","Arjovsky, Martin; Bottou, Léon; Gulrajani, Ishaan; Lopez-Paz, David","Invariant Risk Minimization","","","","10.48550/arXiv.1907.02893","http://arxiv.org/abs/1907.02893","We introduce Invariant Risk Minimization (IRM), a learning paradigm to estimate invariant correlations across multiple training distributions. To achieve this goal, IRM learns a data representation such that the optimal classifier, on top of that data representation, matches for all training distributions. Through theory and experiments, we show how the invariances learned by IRM relate to the causal structures governing the data and enable out-of-distribution generalization.","2020-03-27","2023-03-12 16:45:36","2023-03-12 16:45:36","2023-03-12 16:45:36","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:1907.02893 [cs, stat]","","/Users/patrickmineault/Zotero/storage/N8VVTUB4/Arjovsky et al. - 2020 - Invariant Risk Minimization.pdf; /Users/patrickmineault/Zotero/storage/XMUBEJ5H/1907.html","","","Computer Science - Artificial Intelligence; Computer Science - Machine Learning; Statistics - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:1907.02893","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZQZE6GRY","conferencePaper","2007","Bottou, Léon","The tradeoffs of large scale learning","NeurIPS","","","","https://proceedings.neurips.cc/paper/2007/file/0d3180d672e08b4c5312dcdafdf6ef36-Paper.pdf","This contribution develops a theoretical framework that takes into account the effect of approximate optimization on learning algorithms. The analysis shows distinct tradeoffs for the case of small-scale and large-scale learning problems. Small-scale learning problems are subject to the usual approximation–estimation tradeoff. Large-scale learning problems are subject to a qualitatively different tradeoff involving the computational complexity of the underlying optimization algorithms in non-trivial ways.","2007","2023-04-18 21:47:34","2023-04-19 00:58:30","","","","","","","","","","","","","","","","","","","","","","","","/Users/patrickmineault/Zotero/storage/EMWXNCDF/Bottou - 2007 - The tradeoffs of large scale learning.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5NDBTBAA","preprint","2023","Garg, Shivam; Tsipras, Dimitris; Liang, Percy; Valiant, Gregory","What Can Transformers Learn In-Context? A Case Study of Simple Function Classes","","","","10.48550/arXiv.2208.01066","http://arxiv.org/abs/2208.01066","In-context learning refers to the ability of a model to condition on a prompt sequence consisting of in-context examples (input-output pairs corresponding to some task) along with a new query input, and generate the corresponding output. Crucially, in-context learning happens only at inference time without any parameter updates to the model. While large language models such as GPT-3 exhibit some ability to perform in-context learning, it is unclear what the relationship is between tasks on which this succeeds and what is present in the training data. To make progress towards understanding in-context learning, we consider the well-defined problem of training a model to in-context learn a function class (e.g., linear functions): that is, given data derived from some functions in the class, can we train a model to in-context learn ""most"" functions from this class? We show empirically that standard Transformers can be trained from scratch to perform in-context learning of linear functions -- that is, the trained model is able to learn unseen linear functions from in-context examples with performance comparable to the optimal least squares estimator. In fact, in-context learning is possible even under two forms of distribution shift: (i) between the training data of the model and inference-time prompts, and (ii) between the in-context examples and the query input during inference. We also show that we can train Transformers to in-context learn more complex function classes -- namely sparse linear functions, two-layer neural networks, and decision trees -- with performance that matches or exceeds task-specific learning algorithms. Our code and models are available at https://github.com/dtsip/in-context-learning .","2023-01-14","2023-04-19 05:08:06","2023-05-14 16:50:07","2023-04-19 05:08:06","","","","","","","What Can Transformers Learn In-Context?","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2208.01066 [cs]","","/Users/patrickmineault/Zotero/storage/B4JUV7EC/Garg et al. - 2023 - What Can Transformers Learn In-Context A Case Stu.pdf; /Users/patrickmineault/Zotero/storage/BU45KQEE/2208.html","","","Computer Science - Computation and Language; Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2208.01066","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7NLMRHGT","preprint","2022","HaoChen, Jeff Z.; Wei, Colin; Gaidon, Adrien; Ma, Tengyu","Provable Guarantees for Self-Supervised Deep Learning with Spectral Contrastive Loss","","","","10.48550/arXiv.2106.04156","http://arxiv.org/abs/2106.04156","Recent works in self-supervised learning have advanced the state-of-the-art by relying on the contrastive learning paradigm, which learns representations by pushing positive pairs, or similar examples from the same class, closer together while keeping negative pairs far apart. Despite the empirical successes, theoretical foundations are limited -- prior analyses assume conditional independence of the positive pairs given the same class label, but recent empirical applications use heavily correlated positive pairs (i.e., data augmentations of the same image). Our work analyzes contrastive learning without assuming conditional independence of positive pairs using a novel concept of the augmentation graph on data. Edges in this graph connect augmentations of the same data, and ground-truth classes naturally form connected sub-graphs. We propose a loss that performs spectral decomposition on the population augmentation graph and can be succinctly written as a contrastive learning objective on neural net representations. Minimizing this objective leads to features with provable accuracy guarantees under linear probe evaluation. By standard generalization bounds, these accuracy guarantees also hold when minimizing the training contrastive loss. Empirically, the features learned by our objective can match or outperform several strong baselines on benchmark vision datasets. In all, this work provides the first provable analysis for contrastive learning where guarantees for linear probe evaluation can apply to realistic empirical settings.","2022-06-23","2023-04-19 05:09:33","2023-04-19 05:09:33","2023-04-19 05:09:33","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2106.04156 [cs, stat]","","/Users/patrickmineault/Zotero/storage/JVFCMJ5M/HaoChen et al. - 2022 - Provable Guarantees for Self-Supervised Deep Learn.pdf; /Users/patrickmineault/Zotero/storage/P7CYBTNG/2106.html","","","Computer Science - Machine Learning; Statistics - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2106.04156","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F5HXNRL3","preprint","2021","Lester, Brian; Al-Rfou, Rami; Constant, Noah","The Power of Scale for Parameter-Efficient Prompt Tuning","","","","10.48550/arXiv.2104.08691","http://arxiv.org/abs/2104.08691","In this work, we explore ""prompt tuning"", a simple yet effective mechanism for learning ""soft prompts"" to condition frozen language models to perform specific downstream tasks. Unlike the discrete text prompts used by GPT-3, soft prompts are learned through backpropagation and can be tuned to incorporate signal from any number of labeled examples. Our end-to-end learned approach outperforms GPT-3's ""few-shot"" learning by a large margin. More remarkably, through ablations on model size using T5, we show that prompt tuning becomes more competitive with scale: as models exceed billions of parameters, our method ""closes the gap"" and matches the strong performance of model tuning (where all model weights are tuned). This finding is especially relevant in that large models are costly to share and serve, and the ability to reuse one frozen model for multiple downstream tasks can ease this burden. Our method can be seen as a simplification of the recently proposed ""prefix tuning"" of Li and Liang (2021), and we provide a comparison to this and other similar approaches. Finally, we show that conditioning a frozen model with soft prompts confers benefits in robustness to domain transfer, as compared to full model tuning.","2021-09-02","2023-04-19 05:09:56","2023-04-19 05:09:56","2023-04-19 05:09:56","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2104.08691 [cs]","","/Users/patrickmineault/Zotero/storage/S37S22N3/Lester et al. - 2021 - The Power of Scale for Parameter-Efficient Prompt .pdf; /Users/patrickmineault/Zotero/storage/5WPHPW94/2104.html","","","Computer Science - Computation and Language","","","","","","","","","","","","","","","","","","","arXiv:2104.08691","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KIJY3AU6","preprint","2021","Nagarajan, Vaishnavh; Andreassen, Anders; Neyshabur, Behnam","Understanding the Failure Modes of Out-of-Distribution Generalization","","","","10.48550/arXiv.2010.15775","http://arxiv.org/abs/2010.15775","Empirical studies suggest that machine learning models often rely on features, such as the background, that may be spuriously correlated with the label only during training time, resulting in poor accuracy during test-time. In this work, we identify the fundamental factors that give rise to this behavior, by explaining why models fail this way {\em even} in easy-to-learn tasks where one would expect these models to succeed. In particular, through a theoretical study of gradient-descent-trained linear classifiers on some easy-to-learn tasks, we uncover two complementary failure modes. These modes arise from how spurious correlations induce two kinds of skews in the data: one geometric in nature, and another, statistical in nature. Finally, we construct natural modifications of image classification datasets to understand when these failure modes can arise in practice. We also design experiments to isolate the two failure modes when training modern neural networks on these datasets.","2021-04-29","2023-04-19 05:11:04","2023-04-19 05:11:04","2023-04-19 05:11:04","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2010.15775 [cs, stat]","","/Users/patrickmineault/Zotero/storage/2IH2HHVF/Nagarajan et al. - 2021 - Understanding the Failure Modes of Out-of-Distribu.pdf; /Users/patrickmineault/Zotero/storage/ID2SRCHK/2010.html","","","Computer Science - Computer Vision and Pattern Recognition; Computer Science - Machine Learning; Statistics - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2010.15775","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ACK5HXZF","preprint","2022","Bubeck, Sébastien; Sellke, Mark","A Universal Law of Robustness via Isoperimetry","","","","10.48550/arXiv.2105.12806","http://arxiv.org/abs/2105.12806","Classically, data interpolation with a parametrized model class is possible as long as the number of parameters is larger than the number of equations to be satisfied. A puzzling phenomenon in deep learning is that models are trained with many more parameters than what this classical theory would suggest. We propose a partial theoretical explanation for this phenomenon. We prove that for a broad class of data distributions and model classes, overparametrization is necessary if one wants to interpolate the data smoothly. Namely we show that smooth interpolation requires $d$ times more parameters than mere interpolation, where $d$ is the ambient data dimension. We prove this universal law of robustness for any smoothly parametrized function class with polynomial size weights, and any covariate distribution verifying isoperimetry. In the case of two-layers neural networks and Gaussian covariates, this law was conjectured in prior work by Bubeck, Li and Nagaraj. We also give an interpretation of our result as an improved generalization bound for model classes consisting of smooth functions.","2022-12-23","2023-04-19 05:11:25","2023-04-19 05:11:25","2023-04-19 05:11:25","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2105.12806 [cs, stat]","","/Users/patrickmineault/Zotero/storage/V3DFGHK5/Bubeck and Sellke - 2022 - A Universal Law of Robustness via Isoperimetry.pdf; /Users/patrickmineault/Zotero/storage/4KEVS4TU/2105.html","","","Computer Science - Machine Learning; Statistics - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2105.12806","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X5YQUH8Z","preprint","2021","Caron, Mathilde; Touvron, Hugo; Misra, Ishan; Jégou, Hervé; Mairal, Julien; Bojanowski, Piotr; Joulin, Armand","Emerging Properties in Self-Supervised Vision Transformers","","","","10.48550/arXiv.2104.14294","http://arxiv.org/abs/2104.14294","In this paper, we question if self-supervised learning provides new properties to Vision Transformer (ViT) that stand out compared to convolutional networks (convnets). Beyond the fact that adapting self-supervised methods to this architecture works particularly well, we make the following observations: first, self-supervised ViT features contain explicit information about the semantic segmentation of an image, which does not emerge as clearly with supervised ViTs, nor with convnets. Second, these features are also excellent k-NN classifiers, reaching 78.3% top-1 on ImageNet with a small ViT. Our study also underlines the importance of momentum encoder, multi-crop training, and the use of small patches with ViTs. We implement our findings into a simple self-supervised method, called DINO, which we interpret as a form of self-distillation with no labels. We show the synergy between DINO and ViTs by achieving 80.1% top-1 on ImageNet in linear evaluation with ViT-Base.","2021-05-24","2023-04-19 05:11:52","2023-04-19 05:11:52","2023-04-19 05:11:52","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2104.14294 [cs]","","/Users/patrickmineault/Zotero/storage/DISN9VCJ/Caron et al. - 2021 - Emerging Properties in Self-Supervised Vision Tran.pdf; /Users/patrickmineault/Zotero/storage/CLQJF45P/2104.html","","","Computer Science - Computer Vision and Pattern Recognition","","","","","","","","","","","","","","","","","","","arXiv:2104.14294","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CWQJ7GBH","preprint","2021","He, Kaiming; Chen, Xinlei; Xie, Saining; Li, Yanghao; Dollár, Piotr; Girshick, Ross","Masked Autoencoders Are Scalable Vision Learners","","","","10.48550/arXiv.2111.06377","http://arxiv.org/abs/2111.06377","This paper shows that masked autoencoders (MAE) are scalable self-supervised learners for computer vision. Our MAE approach is simple: we mask random patches of the input image and reconstruct the missing pixels. It is based on two core designs. First, we develop an asymmetric encoder-decoder architecture, with an encoder that operates only on the visible subset of patches (without mask tokens), along with a lightweight decoder that reconstructs the original image from the latent representation and mask tokens. Second, we find that masking a high proportion of the input image, e.g., 75%, yields a nontrivial and meaningful self-supervisory task. Coupling these two designs enables us to train large models efficiently and effectively: we accelerate training (by 3x or more) and improve accuracy. Our scalable approach allows for learning high-capacity models that generalize well: e.g., a vanilla ViT-Huge model achieves the best accuracy (87.8%) among methods that use only ImageNet-1K data. Transfer performance in downstream tasks outperforms supervised pre-training and shows promising scaling behavior.","2021-12-19","2023-04-19 05:12:10","2023-04-19 05:12:10","2023-04-19 05:12:10","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2111.06377 [cs]","","/Users/patrickmineault/Zotero/storage/VILLQ59S/He et al. - 2021 - Masked Autoencoders Are Scalable Vision Learners.pdf; /Users/patrickmineault/Zotero/storage/PT7R2QT4/2111.html","","","Computer Science - Computer Vision and Pattern Recognition","","","","","","","","","","","","","","","","","","","arXiv:2111.06377","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VDMKIPK8","conferencePaper","2021","Bender, Emily M.; Gebru, Timnit; McMillan-Major, Angelina; Shmitchell, Shmargaret","On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜","Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency","978-1-4503-8309-7","","10.1145/3442188.3445922","https://dl.acm.org/doi/10.1145/3442188.3445922","The past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models, especially for English. BERT, its variants, GPT-2/3, and others, most recently Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder values, and encouraging research directions beyond ever larger language models.","2021-03-01","2023-04-19 05:12:31","2023-04-19 05:12:31","2023-04-18","610–623","","","","","","On the Dangers of Stochastic Parrots","FAccT '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/patrickmineault/Zotero/storage/VEFRN9ZN/Bender et al. - 2021 - On the Dangers of Stochastic Parrots Can Language.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GSZ6HHA2","preprint","2021","Miller, John; Taori, Rohan; Raghunathan, Aditi; Sagawa, Shiori; Koh, Pang Wei; Shankar, Vaishaal; Liang, Percy; Carmon, Yair; Schmidt, Ludwig","Accuracy on the Line: On the Strong Correlation Between Out-of-Distribution and In-Distribution Generalization","","","","10.48550/arXiv.2107.04649","http://arxiv.org/abs/2107.04649","For machine learning systems to be reliable, we must understand their performance in unseen, out-of-distribution environments. In this paper, we empirically show that out-of-distribution performance is strongly correlated with in-distribution performance for a wide range of models and distribution shifts. Specifically, we demonstrate strong correlations between in-distribution and out-of-distribution performance on variants of CIFAR-10 & ImageNet, a synthetic pose estimation task derived from YCB objects, satellite imagery classification in FMoW-WILDS, and wildlife classification in iWildCam-WILDS. The strong correlations hold across model architectures, hyperparameters, training set size, and training duration, and are more precise than what is expected from existing domain adaptation theory. To complete the picture, we also investigate cases where the correlation is weaker, for instance some synthetic distribution shifts from CIFAR-10-C and the tissue classification dataset Camelyon17-WILDS. Finally, we provide a candidate theory based on a Gaussian data model that shows how changes in the data covariance arising from distribution shift can affect the observed correlations.","2021-10-07","2023-04-19 05:12:51","2023-04-19 05:12:51","2023-04-19 05:12:51","","","","","","","Accuracy on the Line","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2107.04649 [cs, stat]","","/Users/patrickmineault/Zotero/storage/JKPI99X2/Miller et al. - 2021 - Accuracy on the Line On the Strong Correlation Be.pdf; /Users/patrickmineault/Zotero/storage/PRICILC9/2107.html","","","Computer Science - Machine Learning; Statistics - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2107.04649","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3T44X2UZ","preprint","2020","Sun, Yu; Wang, Xiaolong; Liu, Zhuang; Miller, John; Efros, Alexei A.; Hardt, Moritz","Test-Time Training with Self-Supervision for Generalization under Distribution Shifts","","","","10.48550/arXiv.1909.13231","http://arxiv.org/abs/1909.13231","In this paper, we propose Test-Time Training, a general approach for improving the performance of predictive models when training and test data come from different distributions. We turn a single unlabeled test sample into a self-supervised learning problem, on which we update the model parameters before making a prediction. This also extends naturally to data in an online stream. Our simple approach leads to improvements on diverse image classification benchmarks aimed at evaluating robustness to distribution shifts.","2020-07-01","2023-04-19 05:13:12","2023-04-19 05:13:12","2023-04-19 05:13:12","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:1909.13231 [cs, stat]","","/Users/patrickmineault/Zotero/storage/H4T2CQM7/Sun et al. - 2020 - Test-Time Training with Self-Supervision for Gener.pdf; /Users/patrickmineault/Zotero/storage/7FZ942H7/1909.html","","","Computer Science - Computer Vision and Pattern Recognition; Computer Science - Machine Learning; Statistics - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:1909.13231","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3GU34VYB","preprint","2020","Kaplan, Jared; McCandlish, Sam; Henighan, Tom; Brown, Tom B.; Chess, Benjamin; Child, Rewon; Gray, Scott; Radford, Alec; Wu, Jeffrey; Amodei, Dario","Scaling Laws for Neural Language Models","","","","10.48550/arXiv.2001.08361","http://arxiv.org/abs/2001.08361","We study empirical scaling laws for language model performance on the cross-entropy loss. The loss scales as a power-law with model size, dataset size, and the amount of compute used for training, with some trends spanning more than seven orders of magnitude. Other architectural details such as network width or depth have minimal effects within a wide range. Simple equations govern the dependence of overfitting on model/dataset size and the dependence of training speed on model size. These relationships allow us to determine the optimal allocation of a fixed compute budget. Larger models are significantly more sample-efficient, such that optimally compute-efficient training involves training very large models on a relatively modest amount of data and stopping significantly before convergence.","2020-01-22","2023-04-19 05:13:42","2023-04-19 05:13:42","2023-04-19 05:13:42","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2001.08361 [cs, stat]","","/Users/patrickmineault/Zotero/storage/SJ6CTB5T/Kaplan et al. - 2020 - Scaling Laws for Neural Language Models.pdf; /Users/patrickmineault/Zotero/storage/2VYW26J9/2001.html","","","Computer Science - Machine Learning; Statistics - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2001.08361","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XIQMB67U","preprint","2019","Ilyas, Andrew; Santurkar, Shibani; Tsipras, Dimitris; Engstrom, Logan; Tran, Brandon; Madry, Aleksander","Adversarial Examples Are Not Bugs, They Are Features","","","","10.48550/arXiv.1905.02175","http://arxiv.org/abs/1905.02175","Adversarial examples have attracted significant attention in machine learning, but the reasons for their existence and pervasiveness remain unclear. We demonstrate that adversarial examples can be directly attributed to the presence of non-robust features: features derived from patterns in the data distribution that are highly predictive, yet brittle and incomprehensible to humans. After capturing these features within a theoretical framework, we establish their widespread existence in standard datasets. Finally, we present a simple setting where we can rigorously tie the phenomena we observe in practice to a misalignment between the (human-specified) notion of robustness and the inherent geometry of the data.","2019-08-12","2023-04-19 05:14:02","2023-04-19 05:14:02","2023-04-19 05:14:02","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:1905.02175 [cs, stat]","","/Users/patrickmineault/Zotero/storage/MJ8DECHD/Ilyas et al. - 2019 - Adversarial Examples Are Not Bugs, They Are Featur.pdf; /Users/patrickmineault/Zotero/storage/2L8MJJFN/1905.html","","","Computer Science - Computer Vision and Pattern Recognition; Computer Science - Machine Learning; Statistics - Machine Learning; Computer Science - Cryptography and Security","","","","","","","","","","","","","","","","","","","arXiv:1905.02175","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6GN6BI5S","journalArticle","2020","Bartlett, Peter L.; Long, Philip M.; Lugosi, Gábor; Tsigler, Alexander","Benign Overfitting in Linear Regression","Proceedings of the National Academy of Sciences","","0027-8424, 1091-6490","10.1073/pnas.1907378117","http://arxiv.org/abs/1906.11300","The phenomenon of benign overfitting is one of the key mysteries uncovered by deep learning methodology: deep neural networks seem to predict well, even with a perfect fit to noisy training data. Motivated by this phenomenon, we consider when a perfect fit to training data in linear regression is compatible with accurate prediction. We give a characterization of linear regression problems for which the minimum norm interpolating prediction rule has near-optimal prediction accuracy. The characterization is in terms of two notions of the effective rank of the data covariance. It shows that overparameterization is essential for benign overfitting in this setting: the number of directions in parameter space that are unimportant for prediction must significantly exceed the sample size. By studying examples of data covariance properties that this characterization shows are required for benign overfitting, we find an important role for finite-dimensional data: the accuracy of the minimum norm interpolating prediction rule approaches the best possible accuracy for a much narrower range of properties of the data distribution when the data lies in an infinite dimensional space versus when the data lies in a finite dimensional space whose dimension grows faster than the sample size.","2020-12","2023-04-19 05:14:23","2023-04-19 05:14:23","2023-04-19 05:14:23","30063-30070","","48","117","","Proc. Natl. Acad. Sci. U.S.A.","","","","","","","","","","","","","arXiv.org","","arXiv:1906.11300 [cs, math, stat]","","/Users/patrickmineault/Zotero/storage/JX6H3HEP/Bartlett et al. - 2020 - Benign Overfitting in Linear Regression.pdf; /Users/patrickmineault/Zotero/storage/QYZ3VBUV/1906.html","","","Computer Science - Machine Learning; Statistics - Machine Learning; Mathematics - Statistics Theory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4GEY573Z","preprint","2019","Oliver, Avital; Odena, Augustus; Raffel, Colin; Cubuk, Ekin D.; Goodfellow, Ian J.","Realistic Evaluation of Deep Semi-Supervised Learning Algorithms","","","","10.48550/arXiv.1804.09170","http://arxiv.org/abs/1804.09170","Semi-supervised learning (SSL) provides a powerful framework for leveraging unlabeled data when labels are limited or expensive to obtain. SSL algorithms based on deep neural networks have recently proven successful on standard benchmark tasks. However, we argue that these benchmarks fail to address many issues that these algorithms would face in real-world applications. After creating a unified reimplementation of various widely-used SSL techniques, we test them in a suite of experiments designed to address these issues. We find that the performance of simple baselines which do not use unlabeled data is often underreported, that SSL methods differ in sensitivity to the amount of labeled and unlabeled data, and that performance can degrade substantially when the unlabeled dataset contains out-of-class examples. To help guide SSL research towards real-world applicability, we make our unified reimplemention and evaluation platform publicly available.","2019-06-17","2023-04-19 05:15:26","2023-04-19 05:15:26","2023-04-19 05:15:26","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:1804.09170 [cs, stat]","","/Users/patrickmineault/Zotero/storage/GN4JEBYC/Oliver et al. - 2019 - Realistic Evaluation of Deep Semi-Supervised Learn.pdf; /Users/patrickmineault/Zotero/storage/BE8B877V/1804.html","","","Computer Science - Machine Learning; Statistics - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:1804.09170","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BB6STB8D","preprint","2020","Jacot, Arthur; Gabriel, Franck; Hongler, Clément","Neural Tangent Kernel: Convergence and Generalization in Neural Networks","","","","10.48550/arXiv.1806.07572","http://arxiv.org/abs/1806.07572","At initialization, artificial neural networks (ANNs) are equivalent to Gaussian processes in the infinite-width limit, thus connecting them to kernel methods. We prove that the evolution of an ANN during training can also be described by a kernel: during gradient descent on the parameters of an ANN, the network function $f_\theta$ (which maps input vectors to output vectors) follows the kernel gradient of the functional cost (which is convex, in contrast to the parameter cost) w.r.t. a new kernel: the Neural Tangent Kernel (NTK). This kernel is central to describe the generalization features of ANNs. While the NTK is random at initialization and varies during training, in the infinite-width limit it converges to an explicit limiting kernel and it stays constant during training. This makes it possible to study the training of ANNs in function space instead of parameter space. Convergence of the training can then be related to the positive-definiteness of the limiting NTK. We prove the positive-definiteness of the limiting NTK when the data is supported on the sphere and the non-linearity is non-polynomial. We then focus on the setting of least-squares regression and show that in the infinite-width limit, the network function $f_\theta$ follows a linear differential equation during training. The convergence is fastest along the largest kernel principal components of the input data with respect to the NTK, hence suggesting a theoretical motivation for early stopping. Finally we study the NTK numerically, observe its behavior for wide networks, and compare it to the infinite-width limit.","2020-02-10","2023-04-19 05:15:48","2023-04-19 05:15:48","2023-04-19 05:15:48","","","","","","","Neural Tangent Kernel","","","","","arXiv","","","","","","","arXiv.org","","arXiv:1806.07572 [cs, math, stat]","","/Users/patrickmineault/Zotero/storage/FY96IFZ5/Jacot et al. - 2020 - Neural Tangent Kernel Convergence and Generalizat.pdf; /Users/patrickmineault/Zotero/storage/D8KL2D7Q/1806.html","","","Computer Science - Machine Learning; Statistics - Machine Learning; Computer Science - Neural and Evolutionary Computing; Mathematics - Probability","","","","","","","","","","","","","","","","","","","arXiv:1806.07572","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FQKC3JPL","preprint","2022","Soudry, Daniel; Hoffer, Elad; Nacson, Mor Shpigel; Gunasekar, Suriya; Srebro, Nathan","The Implicit Bias of Gradient Descent on Separable Data","","","","10.48550/arXiv.1710.10345","http://arxiv.org/abs/1710.10345","We examine gradient descent on unregularized logistic regression problems, with homogeneous linear predictors on linearly separable datasets. We show the predictor converges to the direction of the max-margin (hard margin SVM) solution. The result also generalizes to other monotone decreasing loss functions with an infimum at infinity, to multi-class problems, and to training a weight layer in a deep network in a certain restricted setting. Furthermore, we show this convergence is very slow, and only logarithmic in the convergence of the loss itself. This can help explain the benefit of continuing to optimize the logistic or cross-entropy loss even after the training error is zero and the training loss is extremely small, and, as we show, even if the validation loss increases. Our methodology can also aid in understanding implicit regularization n more complex models and with other optimization methods.","2022-07-19","2023-04-19 05:16:11","2023-04-19 05:16:11","2023-04-19 05:16:11","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:1710.10345 [cs, stat]","","/Users/patrickmineault/Zotero/storage/AG9RZPAK/Soudry et al. - 2022 - The Implicit Bias of Gradient Descent on Separable.pdf; /Users/patrickmineault/Zotero/storage/723DKFE7/1710.html","","","Computer Science - Machine Learning; Statistics - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:1710.10345","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U7F779J2","preprint","2019","Frankle, Jonathan; Carbin, Michael","The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks","","","","10.48550/arXiv.1803.03635","http://arxiv.org/abs/1803.03635","Neural network pruning techniques can reduce the parameter counts of trained networks by over 90%, decreasing storage requirements and improving computational performance of inference without compromising accuracy. However, contemporary experience is that the sparse architectures produced by pruning are difficult to train from the start, which would similarly improve training performance. We find that a standard pruning technique naturally uncovers subnetworks whose initializations made them capable of training effectively. Based on these results, we articulate the ""lottery ticket hypothesis:"" dense, randomly-initialized, feed-forward networks contain subnetworks (""winning tickets"") that - when trained in isolation - reach test accuracy comparable to the original network in a similar number of iterations. The winning tickets we find have won the initialization lottery: their connections have initial weights that make training particularly effective. We present an algorithm to identify winning tickets and a series of experiments that support the lottery ticket hypothesis and the importance of these fortuitous initializations. We consistently find winning tickets that are less than 10-20% of the size of several fully-connected and convolutional feed-forward architectures for MNIST and CIFAR10. Above this size, the winning tickets that we find learn faster than the original network and reach higher test accuracy.","2019-03-04","2023-04-19 05:17:01","2023-04-19 05:17:01","2023-04-19 05:17:01","","","","","","","The Lottery Ticket Hypothesis","","","","","arXiv","","","","","","","arXiv.org","","arXiv:1803.03635 [cs]","","/Users/patrickmineault/Zotero/storage/6TJ6KYMG/Frankle and Carbin - 2019 - The Lottery Ticket Hypothesis Finding Sparse, Tra.pdf; /Users/patrickmineault/Zotero/storage/QTET8VW5/1803.html","","","Computer Science - Artificial Intelligence; Computer Science - Machine Learning; Computer Science - Neural and Evolutionary Computing","","","","","","","","","","","","","","","","","","","arXiv:1803.03635","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XAKELA2H","preprint","2017","Neyshabur, Behnam; Bhojanapalli, Srinadh; McAllester, David; Srebro, Nathan","Exploring Generalization in Deep Learning","","","","10.48550/arXiv.1706.08947","http://arxiv.org/abs/1706.08947","With a goal of understanding what drives generalization in deep networks, we consider several recently suggested explanations, including norm-based control, sharpness and robustness. We study how these measures can ensure generalization, highlighting the importance of scale normalization, and making a connection between sharpness and PAC-Bayes theory. We then investigate how well the measures explain different observed phenomena.","2017-07-06","2023-04-19 05:17:20","2023-04-19 05:17:20","2023-04-19 05:17:20","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:1706.08947 [cs]","","/Users/patrickmineault/Zotero/storage/J3EH3A63/Neyshabur et al. - 2017 - Exploring Generalization in Deep Learning.pdf; /Users/patrickmineault/Zotero/storage/RJGX2NCK/1706.html","","","Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:1706.08947","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3EH3XM6H","preprint","2017","Finn, Chelsea; Abbeel, Pieter; Levine, Sergey","Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks","","","","10.48550/arXiv.1703.03400","http://arxiv.org/abs/1703.03400","We propose an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, our method trains the model to be easy to fine-tune. We demonstrate that this approach leads to state-of-the-art performance on two few-shot image classification benchmarks, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies.","2017-07-18","2023-04-19 05:17:45","2023-04-19 05:17:45","2023-04-19 05:17:45","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:1703.03400 [cs]","","/Users/patrickmineault/Zotero/storage/4UZEAG3T/Finn et al. - 2017 - Model-Agnostic Meta-Learning for Fast Adaptation o.pdf; /Users/patrickmineault/Zotero/storage/59WSRNHL/1703.html","","","Computer Science - Computer Vision and Pattern Recognition; Computer Science - Artificial Intelligence; Computer Science - Machine Learning; Computer Science - Neural and Evolutionary Computing","","","","","","","","","","","","","","","","","","","arXiv:1703.03400","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VCQP4E2S","preprint","2012","Schoelkopf, Bernhard; Janzing, Dominik; Peters, Jonas; Sgouritsa, Eleni; Zhang, Kun; Mooij, Joris","On Causal and Anticausal Learning","","","","10.48550/arXiv.1206.6471","http://arxiv.org/abs/1206.6471","We consider the problem of function estimation in the case where an underlying causal model can be inferred. This has implications for popular scenarios such as covariate shift, concept drift, transfer learning and semi-supervised learning. We argue that causal knowledge may facilitate some approaches for a given problem, and rule out others. In particular, we formulate a hypothesis for when semi-supervised learning can help, and corroborate it with empirical results.","2012-06-27","2023-04-19 05:19:20","2023-04-19 05:19:20","2023-04-19 05:19:20","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:1206.6471 [cs, stat]","","/Users/patrickmineault/Zotero/storage/TAUY85AC/1206.html; /Users/patrickmineault/Zotero/storage/BLCXFQVW/Schölkopf et al. - 2012 - On causal and anticausal learning.pdf","","","Computer Science - Machine Learning; Statistics - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:1206.6471","","","","","","","","","","","","","","","","","","","","","","","","","","",""